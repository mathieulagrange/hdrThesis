\section{Introduction}

On considèrera ici qu'un signal sonore est un signal réel discret, échantillonné à une fréquence de 40 kHz. Ce signal peut provenir d'une version quantifié, mais on supposera que le pas de quantification est suffisament réduit pour introduire une dégradation qui soit négligeable. On notera ce signal $s[n]$, il peut être observé sur un intervalle de temps donné, correspondant à un certain nombre d'échantillons temporels $s[n], 0<n<N-1$ souvent appelé intervale d'observation, support ou champ réceptif. Je n'évoquerai pas ici la version continue du signal, l'expression $f(x)$ devant donc se comprendre comme l'application d'une fonction plus ou moins bien définie à un signal $x$ ou une représentation particulière de ce signal.

Egalement, le terme modélisation étant fortement polysémique, il me paraît important de préciser l'usage que je ferais du terme "modèle de son". Un modèle de son désigne pour moi une représentation du signal sonore qui permette de modifier ce signal de manière cohérente avec certaines contraintes exprimées par des dimensions physiques d'intérêt pour une tâche donnée ou la perception qu'en aurait un être humain. On notera $Pe(x)$, l'opérateur de perception humaine du signal $x$. On suit alors un processus dit "d'analyse/synthèse". La phase d'analyse $A$, à partir d'un signal $x$, produit un modèle $X$ et la phase de synthèse $S$, à partir de ce modèle $X$, produit un signal $\tilde{x}=Sy(An(x))$.

Trois critères d'évaluation émergent alors pour ce modèle :
\begin{enumerate}
  \item fidélité : est'il capable de ne pas produire d'artefacts ($Pe(s) \sim Pe(\tilde{s})$)
  \item manipulabilité (expressivité) : est'il capable de mettre à disposition des mécanismes de manipulation tels que $Pe(Sy(X')) \sim Pe'(Sy(X))$.
  \item flexibilité : capacité du modèle à s'appliquer à tout type de signal sonore d'intérêt
\end{enumerate}

L'intuition ici, largement suivie dans la communauté des sciences des données est que, pour tout processus observable, il existe un modèle de ce processus dans lequel des manipulations basé sur des opérateurs mathématiques simples "font sens". On jugera alors la qualité du modèle par sa capacité à proposer de nouvelles approximations de réalisations de ce processus qui soient plausibles (dans notre cas, valide perceptivement)\marginnote{Par exemple, en considérant le signal temporel, on peut aisément manipuler l'intensité perçue en multipliant tout les échantillons par une constante. Ce modèle ne permet par contre pas (sans grosses approximations) de manipuler la hauteur perçue}.

Cette approche se distingue clairement des approches dites "modèles physiques" qui modélisent explicitement le processus mécanique, la qualité du son étant alors censée être la résultante d'une bonne modélisation du système physique dont la mise en vibration est à l'origine du signal sonore.

Pour terminer cette introduction par une note historique, dans la communauté traitement du signal, on parle alors souvent de modèle paramétrique, dans le sens où le modèle dispose d'un ensemble réduit de paramètres qui peuvent être explicitement manipulés pour influer sur l'objet modélisé. L'usage du terme "paramétrique" est néanmoins peu clair, et utilisé avec plus ou moins de bonheur dans la littérature. Je préférerai donc le distinguo entre "modèle" et "transformée". Un modèle expose donc pour moi un ensemble de paramètres manipulables, une transformée étant plus un outil de description.

Précisons ensuite l'intervalle temporel dénommé par "long terme". Cela désigne pour moi une durée à partir de laquelle le signal sonore ne peut plus raisonnablement être considérée comme stationnaire.

De par nos connaissances sur les propriétés physiques de l'organe phonatoire, il est par exemple commun de considérer que le signal de parole est localement stationnaire sur un intervalle de 25 ms. Comme on peut le voir sur la figure, il est bien entendu que . Il me paraît plus juste de motiver ce choix par l'assertion suivante: il est raisonnable perceptivement d'approximer le signal de parole avec un modèle stationnaire par morceaux à partir du moment où ces morceaux sont d'une durée inférieure à 25ms.

La dénomination "long terme" étant dépendante du degré de stationarité du signal étudié, il n'est donc pas possible de fixer une durée pour tout type de signaux sonores à partir de laquelle la dénomination "long terme" est appropriée. On considérera néanmoins dans les études discutées dans ce document qu'un intervalle de temps "long terme" désigne un intervalle de temps supérieur ou égal à la seconde.

Retrieved from Ladefoged (2006), A Course In Phonetics http://www.cog.jhu.edu/courses/325-f2004/ladefoged/course/chapter8/figure8.html

phonemes.jpg

\section{Typologie sonore}

Il est bien entendu que même si l'on souhaite que notre modèle soit flexible, on ne souhaite pas nécessairement que notre modèle soit capable de modéliser tout les signaux possibles. On supposera donc que certaines propriétés d'invariance existent, cad que même si une seconde de son échantillonnée à 44kHz est représenté dans $R^44000$, les paramètres du modèles\marginnote{Ou variable latente, ou encore code} varient dans un espace de dimension bien plus réduit. J'adhère à cette supposition pour de simples raisons d'observations physiques. En prenant l'exemple du signal de parole, il est bien entendu que le son produit est le résultat d'une interaction complexe entre un ensemble d'éléments qui ont une certaine plasticité. Il en reste néanmoins évident que les déformations possibles de l'ensemble de ces éléments sont bornées.

On s'attachera ici à présenter succintement de grandes de signaux sonores que l'on considère d'intérêt, ainsi qu'une dichotomie présente dans toutes ces classes qui permettra d'assoir notre critique des outils de modélisation mis à notre disposition.

\begin{itemize}
  \item parole : sons voisés <a>, <o> / sons plosifs <pe>, <qe>
  \item vocalisation animale : hululement de chouettes / clics de localisation de chauve souris
  \item musique : chant lyrique / percussions
  \item mécanique : ventilation / marteau piqueur
  \item environnementaux : vent faisant siffler des câbles / gouttes de pluie
\end{itemize}\marginnote{Cette typologie est arbitraire, mais suffisante pour les besoins du propos. Elle est grossièrement ordonnée par période d'intérêt important de la communauté de traitement du signal. Le traitement de la parole ayant connu un essor dans les années 1970, la bio acoustique un peu plus tard, la musique dans les années 2000 et les signaux environnementaux dans les années 2010.}

On remarquera que les exemples donnés pour chaque classe sont judicieusement choisis. Sans rentrer dans les détails, on notera que l'on retrouve certains sons portant une structuration fréquentielle forte et d'autres une structuration temporelle forte et que la plupart des sons naturels sont une composition de ces deux types de structures. Il est donc néccessaire pour atteindre nos objectifs de disposer d'outils performants pour modéliser conjointement ces deux types de structures.

\section{Approches temps / fréquence (1)}

Lorsque l'on cherche à décrire un son, deux dimensions émergent : l'intensité et la hauteur \marginnote{Dans une optique écologique, pouvoir être averti de la puissante mise en vibration de larges volumes est un atout décisif pour la survie.}. Ces deux dimensions étant respectivement intimement liés au volume et à la fréquence, il est normal de constater que la plupart des modèles de son permettent de manipuler ces deux dernières quantités et ce, de manière dynamique \textit{i.e.} au cours du temps.

En supposant le signal sonore stationnaire sur l'intervalle d'observation, l'outil privilégié pour ce faire est la transformée de Fourier discrète. Cette transformée projette le signal sur une base d'exponentielles complexes:
\begin{eqnarray}
  S[m] &=& \sum_{n=0}^{N} s[n] e^{-jnm/F_s} \\
  s[n] &=&\frac{1}{N}
\end{eqnarray}

Ces exponentielles formant une base, il est possible de revenir au signal d'origine (IDFT(DFT(x))=x). Cette transformée est donc inversible, mais n'est pas à échantillonnage critique car $s\in \mathbb{R}$  et $S in \mathbb{C}$\marginnote{On la calcule de manière efficace grâce à des algorithmes de transformée de Fourier rapides qui exploitent, pour le plus connu d'entre eux, des longueurs de supports en puissance de deux.}.

En considérant le module de cette transformée, on manipule directement l'intensité du son à la fréquence donnée. Le spectre de phase est lui souvent négligé dans les modèles, car il est beaucoup plus difficile à interpréter. Ceci constitue un handicap majeur pour tout les modèles de sons basés sur la transformée de Fourier car cela, comme cela sera discuté dans la suite, pose bien souvent une limite sur la propriété de naturalité, le module et l'exposant étant mathématiquement intrinsèquement lié.

Considérons un premier signal "éprouvette" constitué de deux sinusoides de fréquence et d'amplitude constante:
\begin{equation}
  s_s[n] =
\end{equation} FIGURE
Il est aisé d'estimer les paramètres d'amplitude et de fréquence grâce à l'estimateur suivant :
\begin{eqnarray}
  a_s &=& \\
  f_s &=&
\end{eqnarray} FIGURE
On peut améliorer la précision de ces estimations en réduisant le pas de quantification de l'axe fréquentiel. On utilise pour cela la technique du "zero padding", qui consiste à concatener une série de valeurs nulles au signal observé. La transformée s'opérant alors sur plus de points, sa précision est augmentée. Il est important de bien garder en mémoire que seule la précision est augmentée, la résolution restant dépendante de la largeur du support temporel. \marginnote{Un large échantillon de méthodes sont disponibles pour améliorer la précision de ces estimations par d'autres moyens moins directs, voir \cite{marchand}.}. Augmenter l'intervalle d'observation va donc non seulement influer sur la précision, mais également sur la résolution de la transformée. Ainsi deux sinusoïdes de fréquences proches pourront être "résolues", cad leurs paramètres pourront être estimés en observant directement le spectre d'amplitude. Dans le cas de plusieurs sinusoides, on remplacera le max par une sélection de pics dans le spectre de puissance et on considèrera l'usage d'une fenêtre de type cosinusoidale (hamming, hanning) pour améliorer la localité fréquentielle.

Egalement, dans le cas multi-composantes, on effectue un fenêtrage du signal observé, souvent. En effet, considérer le signal sur un intervalle de temps défini par la largeur de la trame revient à fenêtré le signal par une fenêtre rectangulaire qui a des propriétés spectrales non déisrables.

EQUATION

On note qu'avec des fenêtres cosinusoidales, comme Hamming ou Hanning, le lobe principal s'élargit, d'où une perte locale de résolution, mais permet de réduit considérablement l'importance des lobes secondaires. FIGURE

Considérons un autre signal "éprouvette" constitué d'un dirac :
\begin{equation}
  s_d[n] =
\end{equation} FIGURE
L'estimation du paramètre d'amplitude et de sa position temporelle est triviale dans le domaine temporel. Cette dernière est par contre beaucoup plus difficile à estimer dans le domaine spectral, du fait du caractère non stationnaire du signal analysé.

Pour palier au caractère non stationnaire à long terme de la plupart des signaux naturels, il est courant d'utiliser la transformée de Fourier à court terme (TFCT). Son principe est d'effectuer une série de transformée de Fourier, chacune sur des fenêtres espacées dans le temps:
\begin{equation}
TFCT =
\end{equation}
En prenant le spectre de magnitude de la TFCT, on obtient le bien connu spectrogramme, un outil de manipulation et de visualisation qui trouve son utilité dans de très nombreux domaines d'application. L'espoir ici est que les erreurs de modélisation des non stationarités du signal seront négligeables du fait du faible support temproels des fenêtres sur lesquels on applique la DFT. \marginnote{Dans le cas classique où les fenêtres se recouvrent de moitié, on peut utiliser la MDCT pour conserver un échantillonnage critique \cite{princen1986analysis}.} FIGURE

En considérant la TFCT, il est alors possible de construire un estimateur "spectral" de la position temporelle de notre dirac:
\begin{equation}
t_d =
\end{equation}
Pour améliorer la précision temporelle de cet estimateur, il est courant de réduire le recouvrement entre fenêtres. Cela suppose bien entendu l'usage d'une fenêtre "à rampe" (triangulaire ou cosinusoidale). La encore, il s'agit d'une amélioration de la précision et non de la résolution. Seule la réduction de l'intervalle d'observation permettant de résoudre la position temporelle de deux diracs.

Aux travers de ces exemples, on voit qu'il est possible d'améliorer dans une certaine mesure la précision des estimations que l'on peut faire à partir d'un plan temps/fréquence obtenu grâce à la TFCT, mais que les résolutions temporelles et fréquentielles reste conflictuellement contraintes par la taille de la fenêtre choisie \marginnote{On parle de variables jointe pour le temps et la fréquence, au même titre que la position et la vitesse en mécanique quantique \cite{heisenberg}}.

Le problème se corse alors sensiblement lorsque l'on considère des signaux qui possèdent une localité temporelle et fréquentielle, ce qui est le cas de la plupart des signaux sonores naturels\marginnote{Un exemple iconique étant la note de piano dont la qualité s'exprime autant du côté de la localité temporelle (netteté de l'attaque) que de la localité fréquentielle (pureté des harmoniques). FIGURE}.

Il paraît alors naturel de considérer des approches à résolution multiples. Tout le problème consiste alors à trouver une représentation qui maximise le potentiel apporté par la multi résolution en terme de fidélité en minimisant la perte en manipulabilité.

L'approche la plus simple concetpuellement consiste, à intervalle régulier, à "empiler" plusieurs DFT de taille différente. FIGURE
La perte d'unicité de la représentation faire que l'on se trouve alors face à un problème intractable de sélection d'où une perte innaceptable en manipulabilité.

La propriété d'unicité de la représentation paraissant incontournable, la seule solution consiste alors à partager judicieusement le plan temps / fréquence de manière à mitiger la contrainte posée par le principe d'incertitude. Un immense travail de la communauté de traitement du signal a été de concevoir ce type de transformée, connue maintenant sous le nom de transformée en "ondelettes". \cite{mallat1989theory}.

Même si les travaux théoriques dans ce domaine ont permis d'ouvrir considérablement les possibilités en terme de conception, je me  tiendrai ici à la forme la plus courante en traitement du signal qui consiste en une construction d'un banc de filtre dyadique à facteur de qualité constant. Ce banc de filtre est constitué d'un ensemble filtres passe bande à l'octave, \textit{i.e.} la fréquence de coupure supérieure est égale à deux fois la fréquence de coupure inférieure. En considérant que le banc de filtre est construit de manière itérative en partant des hautes fréquences, et en notant que le signal observé est d'une durée limitée, une partie du spectre en basse fréquence ne peut être capturé. On ajoute alors un filtre passe bas "de terminaison" qui permet de préserver l'unicité de la représentation, souvent appelé "fonction d'échelle". Les sorties de ce banc de filtres peuvent être ensuite rééchantillonné à une fréquence de Nyquist correspondante à la largeur de la bande d'octave du filtre considéré QUID DU FILTRE DE TERMINAISON ?.

Comme le montre les travaux pionniers en ce domaine \cite{kronland1987analysis}, l'application de la transformée en ondelettes paraît avoir d'excellentes propriétés pour le traitement de l'audio, en particulier cette capacité à proposer une analyse multirésolution en préservant la propriété d'unicité. Quelques décennies plus tard, on peut faire le constat que l'utilisation de la transformée en ondelettes reste marginale en traitement de l'audio.

Une première explication peut être que les fonctions de bases de la transformée en ondelettes, \textit{i.e.} les réponses impulsionnelles des filtres passe bande ont des formes particulières, non adaptées à l'audio. On peut en effet aisément retenir cet argument pour des ondelettes de Daubechies de faible longueur, pour des longueurs plus élevées, ou par les ondelettes de morlet.

parler de stabilite à la déformation mel et redressement implicite

lewicki ??

Ceci pourrait expliquer pourquoi cette transformée à pris son essor dans le domaine du traitement d'image, où les discontinuités sont beaucoup plus fortes que pour les signaux sonores\marginnote{En effet, chaque contour d'un objet amène une discontinuité importante dans l'espace couleur, qui, dans le cas du codage, se doit d'être représenté en détail, sous peine d'engendrer des artéfacts de type "lissage" très pénalisant et dans le cas de la reconnaissance, apporte des éléments d'interprétation très importants.}

Une seconde, finalement peut être plus déterminante, peut avoir trait à l'interprétabilité et à la manipulabilité de la transformée. L'interprétation du spectrogramme est extrêmement intuitive et permet une analyse fine du contenu spectral d'un signal audio, ceci avec peu d'expertise. L'interprétation du scaleogram (l'équivalent pour la transformée en ondelettes) reste bien. En ce qui concerne la manipulabilité, l'échantillonage non régulier en temps et en fréquence ne simplifie pas l'expression des transformations que l'ont souhaitent généralement opérer (transposition, étirement, ...).

En tout état de cause, dans le domaine de l'audio, la grande majorité des systèmes de traitement considère une représentation de type TFCT, avec des paramètres de résolution et de précision constants, et adaptés à la tâche. Ce n'est que dans les applications de codage que l'on trouve des mécanismes à résolution multiple de type alterné, implanté grâce des MDCT de trois largeurs de support\cite{brandenburg1999mp3}. Au sein du codeur, une heuristique détermine parmi les trois résolutions poossibles, la résolution la plus adaptée au vu du signal contenu dans l'intervalle d'observation considéré. Cet échantillonage non régulier de l'axe temporel permet une meilleure fidélité et flexibilité si l'heuristique est adaptée, ceci au détriment de la manipulabilité, le plan temps/fréquence induit étant non régulier, ce qui n'est généralement pas un factuer  limitant dans des chaînes de codage.

On considère donc ici que dans l'intervalle d'observation, une source sonore est dominante et que le type de source est structurée soit de manière temporelle soit de manière spectrale. Dans le cas d'un contenu polyphonique avec une structure saillante à la fois en temps et en fréquence, cette approche se révèle bien entendu inefficace. La définition d'une méthode d'analyse/synthèse multirésolution reste donc, avec les éléments présentés ici, un problème encore largement ouvert.

\section{Modélisation sinusoïdale court terme (1)}

Lorsque l'on observe un spectrogramme un instrument de musique tonal (FIGURE), il apparait clairement que l'énergie est concentrée en un ensemble réduit de zones fréquentielles. On dit que ces signaux sont parcimonieux en fréquence. C'est, dans une certaine mesure le cas de la parole\marginnote{En tout cas, il est clair que la "charge sémantique" est portée par cette partie du signal de la parole. En supposant que le récepteur (l'oreille) est capable de décomposer les sons sur l'axe fréquentiel, il fait sens écologiquement de procéder ainsi. Comme le montre les exemples de "sine-wave speech", quelques sinusoïdes (3 ou 4) judicieusement placées aux zones de résonances formantiques suffisent à rendre le signal intelligible \url{http://webpages.mcgill.ca/staff/Group2/abregm1/web/downloadstoc.htm#23}.}.

En suivant cette observation, on peut considérer l'heuristique des maxima locaux pour extraire de chaque spectre du spectrogramme un ensemble de "pics spectraux", ou "atomes" :

Même si cette technique est motivée par la parcimonie, elle se révèle très robuste à la réduction de cette dernière. En effet, l'expansion de Karhunen Loeve de signaux bruités montre qu'une représentation sinusoidale de ce type de signaux est valide, à condition que les pics soient suffisamment nombreux et de fréquence suffisamment proche pour que la densité spectrale de puissance dans ces zones varie lentement dans le temps \cite{mcaulay} (EXEMPLES SONORES ?). En pratique, dans un compromis favorisant la fidélité et la flexibilité au détriment de la manipulabilité, on choisira $P$ en fonction de contraintes de complexité.

Les paramètres de fréquence, d'amplitude, et de phase de chaque atome peuvent être estimées grâce aux informations données directement par la transformée de Fourier :
\begin{eqnarray}
\end{eqnarray}
Comme évoqué dans la partie précédente, la précision de ces estimations peut être améliorer par des techniques de sur échantillonage en fréquence et en temps, au détriment du coût de calcul. Ceci étant dit, les limites de cette technique sont bien illustrés dans la figure suivante :

% voice_1024_512.eps

Ce problème d'estimation dépassant largement la problématique de la modélisation du signal audio, un effort conséquent d'amélioration des ces estimateurs a été effectué par la communauté de traitement du signal. Les approches les plus efficaces et les plus élégantes pour ce faire se basent sur des relations entre les paramètres spectraux de plusieurs transformées de Fourier effectuées après différents traitements du signal observé. La technique du reassignement spectral\cite{auger1995improving} considère le rapport entre la DFT du signal fenêtré et la DFT du signal fenêtré par la dérivée de la fenêtre :
\begin{equation}

\end{equation}
En considérant le rapport de la DFT du signal et celle de la DFT de la dérivée du signal, on obtient une autre série d'estimateurs. On a prouvé l'équivalence théorique de ces dernières à la technique du réassignement, supportée par des expérimentations montrant des performances similaires \cite{lagrangeJaes07}.

L'usage de ces estimateurs permet de reconsidérer l'heuristique utilisée pour sélectionner les atomes candidats. En effet, dans un objectif de manipulabilité, il est important que  avec l'observation  soit en adéquation avec le modèle utilisé. De nombreux critères dits de "sinusoidalité" ont été proposés pour ce faire. Pour ce faire, nous avons proposée une approche \cite{peak-selection} L'algorithme proposé consiste a corréler, pour chaque pic candidat, sa réponse fréquentielle à celle du spectre d'une sinusoïde dont les paramètres sont résultant du processus d'estimation. Le degré de corrélation permet alors de quantifier la pertinence du modèle.
Une étude comparative \cite{wells2010comparative} semble montrer l'intérêt de cette approche en pratique.

Dans cet algorithme, les références au modèle sont ici construites dynamiquement mais peuvent aussi être échantillonnées. On se rapproche alors du principe des algorithmes de poursuites de sous espaces \cite{}. Le principe ici est de s'affranchir des contraintes de la base de Fourier en disposant d'un (très) large dictionnaire d'atomes redondants et de déterminer la combinaison optimale de ces atomes permettant de réduire l'erreur d'approximation.

L'algorithme proposé par Zhang et Mallat \cite{mallat1993matching} permet de résoudre efficacement ce problème en considérant un algorithme glouton, où, itérativement, l'atome mis à l'échelle ayant la meilleure corrélation avec le signal résiduel (égal au signal d'origine au début de l'algorithme) est sélectionné.

L'application directe de ce type d'algorithme à des signaux musicaux peut poser des problèmes, dont certains ont été étudiés par Rémi Gribonval. Par exemple, dans le cas de signaux non stationnaire en amplitude, l'algorithme aura tendance à construire des approximations non satisfaisantes.

La figure illustre deux cas typiques de ce type de non stationarité rencontrés dans les signaux musicaux. Le premier consiste en une composante sinusoidale dont l'amplitude est modulée de manière sinusoidale. C'est une modulation typique d'un tremolo. Le second consiste en une composante sinusoidale dont l'amplitude est modulée exponentiellement. C'est une modulation typique d'une corde frappée ou pincée comme le piano ou le clavecin.

Dans le cas a), l'algorithme MP identifie d'abord une composante avec un support temporel couvrant l'intégralité du signal. Deux autres composantes viennent ensuite annuler certaines parties de cette première. Dans le cas b), le changement abrupt d'énergie étant dificcilement modélisable aves les fonctions de base à disposition, de nombreuses composantes d'annulation sont nécessaires, amenant à un effet de pré écho, l'énergie ajoutée n'étant que partiellement enlevée.

gribonval.png

Pour palier à ces problèmes, des contraintes de non negativité ont été proposé pour améliorer l'algorithme de poursuite \cite{gribonval1996sound}. En réduisant les contributions destructives (enlever de l'énergie amené par des atomes selectionés mais non présente dans le signal d'origine), cette approche est plus efficace au sens où l'énergie globale des atomes (somme des envelopes des atomes) est plus faible cas a)  et plus fidèle cas b).

Il est difficile de critiquer ces approches de poursuites dans le sens où sa pertinence vis à vis de la tâche va grandement dépendre du degré de pertinence du dictionnaire choisi. On notera tout de même que ces approches sont construites avec un objectif d'appromixation et non d'identification. Par exemple dans le cas (a), les deux algorithmes de poursuites sont tout deux à même de bien approximer le signal, mais "n'identifie" pas le phénomène, le dictionnaire n'ayant pas ce type de forme \marginnote{On prefera en tout état de cause la seconde approximation pour des raisons de simplicité. PARLER DE L'INDETERMINATION ?}.

A ce titre, on se trouve donc avec un compromis de modèle favorisant la fidélité et la flexibilité, au détriment de la manipulabilité. Il est en effet difficile, dans le cas d'un dictionnaire très largement redondant de déterminer des fonctions simples de manipulation.

Ces approches, comme la transformée en ondelettes, ont trouvés application plutôt dans le domaine du traitement de l'image, où le caractère hautement non stationnaire des transitions entre objets sont très mal approximé par des fonctions régulières comme celle de Fourier.

\section{Approches sinusoïdales long terme (2)}

\cite{mcaulay}

L'approche court terme effectue des observations discrètes d'un processus de production sonore qui lui est par essence continu. Dans le cas de nombreux instruments de musique, il est raisonnable de considérer que ce processus continu est approximable par une somme de sinusoïdes dont les paramètres varient \textsl{lentement}\marginnote{Typiquement, de l'ordre de la dizaine de Hertz.} dans le temps :
\begin{equation}

\end{equation}

En supposant les paramètres connus, le processus de synthèse est aisée à mettre en oeuvre avec les moyens computationels actuels\margninote{Dans le cas d'un nombre de sinusoide très grand des algorithmes de "pruning" peuvent être mis en place \cite{lagrangeDafx01}.}. Il est également aisé de mette en place des modifications du signal d'intérêt comme la translation, la transposition, ou encore l'étirement, simplement en manipulant les paramètres\marginnote{Ces transformations sont également à faible coût, les paramètres étant échantillonnés à une fréquence environ 1000 fois plus faible que le signal}. On est donc typiquement dans un compromis qui favorise la fidélité et la manipulabilité. Ceci se fait, on le verra par la suite, au détriment de la flexibilité, ce modèle étant applicable à un champ restreint de signaux sonores.

Dans notre étude des algorithmes d'estimation des paramètres long terme, on supposera que le signal analysé est composé d'une ou plusieurs sources dont une grande partie de leur énergie peut être correctement approximée par ce modèle. On fera état ici des approches dites de "restoration" de continuité, qui considèrent connu un modèle court terme du signal analysé mais dont la fiabilité n'est pas pré supposée\marginnote{Ce n'est bien entendu pas la seule approche possible. On peut notamment citer les travaux de Corentin Dubois qui a étudié l'application des techniques de filtrage particulaire pour l'estimation conjointe des paramètres court terme et long terme \cite{dubois2005tracking}, travail étendu à des modèles de sources harmoniques \cite{dubois2007joint}}.


Dans l'article séminal de George Mac Aulay \& al, il est donc proposé "d'identifier" ces composantes long terme en reliant entre eux des atomes de trames successives. L'algorithme proposé est itératif. Supposant un ensemble de composantes long terme à la trame $t$, on va chercher à prolonger ces composantes à la trame $t+1$ en commençant par la composante de plus basse fréquence, tel que la différence entre $$ et $$ est minimale :
\begin{equation}

\end{equation}
Dans un principe d'allocation exclusif, cet atome est dès lors réservé, indisponible pour la suite du déroulement de l'algorithme. Chaque atome non réservé devient alors une composante long terme qui sera potentiellement prolongée aves des atomes de la trame suivante\marginnote{On note ici que la structure de données se complexifie sensiblement par rapport à la plupart de celles introduites avec des outils de traitement du signal canoniques, amenant une approche plus "informatique" à une problématique de traitement du signal. Cette modélisation plus "riche" a permis une flexibilité de manipulation qui a donner lieu à un large ensemble d'heuristiques qui ne seront pas étudiées ici, même si elles ont leur intérêt pour la qualité du rendu sonore de ce type d'approche.}.

La contrainte exprimée par l'équation \ref{} favorise des trajectoires fréquentielle constantes. Dans le cas d'un modèle court terme de bonne qualité, par exemple dans le cas d'un signal monophonique à structure harmonique cette heuristique peut être raisonnable. Dans le cas de signaux bruités et/ou polyphoniques, il est utile d'améliorer la finnesse du prédicteur en considérant par exemple un prédicteur linéaire appliqué aux séries temporelles des paramètres long terme. Le faible échantillonage de ces séries temporelles nécessite des prédicteurs particulier comme la méthode de Burg \cite{}.

La contrainte d'évolution lente des paramètres dans le cas d'un modèle stationnaire (prédicteur constant) se traduit nautrellement par un seuil sur le delta de fréquence. L'amélioration du prédicteur nous a également amené à reconsidérer cette étape de sélection.

Les bons résultats en terme de rendu sonore obtenu dans le cas  de la modélisation long terme sous contrainte de débit \cite{lagrangeTaslp06} et l'interpolation de données manquantes \cite{lagrangeJaes05}, montre l'intérêt de la modélisation des modulations long terme, au moins du point de vue perceptif.

Fort de cette observation, Martin Raspaud à étudier un modèle long terme hiérarchique qui permet des manipulations riche comme par exemple de l'étirement temporel de notes vibrées. Le principe est de considérer les paramètres long terme comme des signaux, eux mêmes modélisables comme des sinusoïdes dont les paramètres évoluent (très) lentement en fonction du temps.

D'une grande élégance formelle, d'une grande expressivité et manipulabilité, le modèle long terme n'a pas pu trouver un large spectre spectre d'application du fait d'un défaut clair de fidélité\marginnote{On peut citer pour exemple le codeur STS de Phillips qui n'a pas réussi a concurrencer les approches MDCT.}.

Certaines approches, dites hybrides, consistant à combiner un modèle long terme avec un modèle de bruit et modèle de transitoires ont été proposées pour palier à ce défaut. On tombe alors dans un problème de sélection de modèles que l'on peut espérer mitiger dans le cas d'un signal monophonique\marginnote{on est alors souvent dans le cas d'une analyse experte ou l'intervention humaine est décisive, ce qui peut avoir son intérêt dans certaines applications} mais qui devient  rapidement insoluble dans le cas polyphonique.

EXPLICITER PLUS LES RAISONS ?

\section{Approches temps / fréquence / modulations (10)}

S'il est clair que la décomposition fréquentielle est de première importance, la manière dont l'énergie module au court du temps au sein de ces bandes de fréquences l'est également \marginnote{On peut citer pour exemple le son éminement désagréable d'un moteur thermique deux temps (type mobylette) qui part le mouvement mécanique induit une modulation typique.}. L'importance perceptive de ce type de modulations est particulièrement bien exemplifiée par un exemple sonore produit par John Chowning où des sinusoides d'amplitude et fréquence au début constantes sont ensuite modulées par un signal synthétique composé d'une composante sinusoidale (pour le vibrato) et d'une composante stochastique. Ce signal modulant est ensuite mis à l'échelle pour chaque harmonique. Il est important de considérer que même si ce signal modulant a été judicieusement choisi, il n'est pas issu d'un processus d'estimation à partir de signaux réels.

L'écoute montre clairement que le caractère naturel, voisé, est sensiblement plus élevé avec l'ajout de la modulation \marginnote{Ce stimuli est disponible ici \url{http://webpages.mcgill.ca/staff/Group2/abregm1/web/snd/Track24.mp3} pour écoute sur le site de Al Bregman dédié à l'ASA. Les spécificités techniques du porcessus de synthèse sont décrites ici : \url{http://webpages.mcgill.ca/staff/Group2/abregm1/web/downloadstoc.htm#24}}.}.

\subsection{Modèles perceptifs}

En regard des études physiologiques relativement anciennes sur la cochlée \cite{}, l'étude des éléments physiologiques en charge du traitement de ces modulations est relativement récente car probablement sensiblement plus difficile a investiguer. On a néanmoins une bonne confiance dans le fait que le système auditif des mammifères dispose d'éléments de traitement dédiés. On citera donc le modèle de Torsten Dau \cite{dau1997modeling} et celui de Shihab Shamma \cite{fritz2003rapid} qui étend le modèle de Dau en ajoutant une troisième dimension : l'échelle.

Shihab Shamma a étudié certaines cellules du cortex auditif primaire du furet, plus particulièrement ce que l'on appelle leur champ de réponse spectro/temporels ("spectro-temporal receptive fields (strf)"). L'animal est contraint au niveau du crâne, et par opération chirugicale, une aiguille permettant de mesurer l'activité électrique est insérée dans le crâne de l'animal et judicieusement placée. Par exposition d'un ensemble de stimuli comportant des modulations, il est alors possible de mesurer ces strf. Au vu de ce type de réponses, Un modèle de traitement de signal est ensuite proposé.

Dans ce modèle, le signal est donc tout d'abord décomposé sur l'axe fréquentiel. La sortie étant un équivalent du spectrogramme qui est ensuite décomposé une nouvelle fois fréquentiellement en temps et en fréquence grâce à des ondellettes bi-dimensionnelles paramétrées avec un facteur d'échelle. La dimension de l'échelle permet de définir le nombre de bandes qui sont conjointement utilisées pour effectuer cette seconde analyse fréquentielle \marginnote{Ces modèles sont bien entendu sujet à débat dans la communauté de neurophysiologie. Par exemple, le facteur d'échelle est pour Dau non nécessaire pour expliquer les données receuillies grâce à son protocole expérimental.}.

\subsection{Scattering d'ondelettes}

scattering temps temps/fréquence \cite{anden2014deep}

modes de jeux



\section{Approches modales (2)}

physique

source / filtre

sons de roulements \cite{LagrangeTasslp10}

marseille \cite{conan2014synthesis}

On se trouve ici à l'intersection entre modélisation statistique et modélisation physique, dans le sens où l'architecture du modèle de son suit un modèle de production .

Les domaines d'application des approches modales comme celles décrites ici. Elles gardent à mon sens un intérêt historique pour mettre en perspective les approches modernes décrites dans la suite.

\section{Approches temporelles (10)}

\cite{wavenet}

\section{Conclusion}

approche source filtre <> latent code

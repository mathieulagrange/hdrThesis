\chapter{Modélisation des signaux sonores}

\section{Introduction}

On considèrera ici qu'un signal sonore est un signal réel discret, échantillonné à une fréquence de 40 kHz. Ce signal peut provenir d'une version quantifié, mais on supposera que le pas de quantification est suffisament réduit pour introduire une dégradation qui soit négligeable. On notera ce signal $s[n]$, il peut être observé sur un intervalle de temps donné, correspondant à un certain nombre d'échantillons temporels $s[n], 0<n<N-1$ souvent appelé intervale d'observation, support ou champ réceptif. Je n'évoquerai pas ici la version continue du signal, l'expression $f(x)$ devant donc se comprendre comme l'application d'une fonction plus ou moins bien définie à un signal $x$ ou une représentation particulière de ce signal.

Egalement, le terme modélisation étant fortement polysémique, il me paraît important de préciser l'usage que je ferais du terme "modèle de son". Un modèle de son désigne pour moi une représentation du signal sonore qui permette de modifier ce signal de manière cohérente avec certaines contraintes exprimées par des dimensions physiques d'intérêt pour une tâche donnée ou la perception qu'en aurait un être humain. On notera $Pe(x)$, l'opérateur de perception humaine du signal $x$. On suit alors un processus dit "d'analyse/synthèse". La phase d'analyse $A$, à partir d'un signal $x$, produit un modèle $X$ et la phase de synthèse $S$, à partir de ce modèle $X$, produit un signal $\tilde{x}=Sy(An(x))$.

Trois critères d'évaluation émergent alors pour ce modèle :
\begin{enumerate}
  \item fidélité : est'il capable de ne pas produire d'artefacts ($Pe(s) \sim Pe(\tilde{s})$)
  \item expressivité : est'il capable de mettre à disposition des mécanismes de manipulation tels que $Pe(Sy(X')) \sim Pe'(Sy(X))$.
  \item versatilité : capacité du modèle à s'appliquer à tout type de signal sonore d'intérêt, \textit{i.e.} les conditions 1 et 2 sont remplies pour tout signal $x$.
\end{enumerate}

L'intuition ici, largement suivie dans la communauté des sciences des données est que, pour tout processus observable, il existe un modèle de ce processus dans lequel des manipulations basé sur des opérateurs mathématiques simples "font sens". On jugera alors la qualité du modèle par sa capacité à proposer de nouvelles approximations de réalisations de ce processus qui soient plausibles (dans notre cas, valide perceptivement)\marginnote{Par exemple, en considérant le signal temporel, on peut aisément manipuler l'intensité perçue en multipliant tout les échantillons par une constante. Ce modèle ne permet par contre pas dans le cas général de manipuler la hauteur perçue.}.

Cette approche se distingue clairement des approches dites "modèles physiques" qui modélisent explicitement le processus mécanique, la qualité du son étant alors censée être la résultante d'une bonne modélisation du système physique dont la mise en vibration est à l'origine du signal sonore.

Pour terminer cette introduction par une note historique, dans la communauté traitement du signal, on parle alors souvent de modèle paramétrique, dans le sens où le modèle dispose d'un ensemble réduit de paramètres qui peuvent être explicitement manipulés pour influer sur l'objet modélisé. L'usage du terme "paramétrique" est néanmoins peu clair, et utilisé avec plus ou moins de bonheur dans la littérature. Je préférerai donc le distinguo entre "modèle" et "transformée". Un modèle expose donc pour moi un ensemble de paramètres manipulables, une transformée étant plus un outil de description.

Précisons ensuite l'intervalle temporel dénommé par "long terme". Cela désigne pour moi une durée à partir de laquelle le signal sonore ne peut plus raisonnablement être considérée comme stationnaire.

De par nos connaissances sur les propriétés physiques de l'organe phonatoire, il est par exemple commun de considérer que le signal de parole est localement stationnaire sur un intervalle de 25 ms. Comme on peut le voir sur la figure, il est bien entendu que . Il me paraît plus juste de motiver ce choix par l'assertion suivante: il est raisonnable perceptivement d'approximer le signal de parole avec un modèle stationnaire par morceaux à partir du moment où ces morceaux sont d'une durée inférieure à 25ms.

La dénomination "long terme" étant dépendante du degré de stationarité du signal étudié, il n'est donc pas possible de fixer une durée pour tout type de signaux sonores à partir de laquelle la dénomination "long terme" est appropriée. On considérera néanmoins dans les études discutées dans ce document qu'un intervalle de temps "long terme" désigne un intervalle de temps supérieur ou égal à la seconde.

Retrieved from Ladefoged (2006), A Course In Phonetics http://www.cog.jhu.edu/courses/325-f2004/ladefoged/course/chapter8/figure8.html

phonemes.jpg

\section{Typologie sonore}

Il est bien entendu que même si l'on souhaite que notre modèle soit versatile, on ne souhaite pas nécessairement que notre modèle soit capable de modéliser tout les signaux possibles. On supposera donc que certaines propriétés d'invariance existent, cad que même si une seconde de son échantillonnée à 44kHz est représenté dans $R^44000$, les paramètres du modèles\marginnote{Ou variables latentes, ou encore code} varient dans un espace de dimension bien plus réduit. J'adhère à cette supposition pour de simples raisons d'observations physiques. En prenant l'exemple du signal de parole, il est bien entendu que le son produit est le résultat d'une interaction complexe entre un ensemble d'éléments qui ont une certaine plasticité. Il en reste néanmoins évident que les déformations possibles de l'ensemble de ces éléments sont bornées.

On s'attachera ici à présenter succintement de grandes familles de signaux sonores que l'on considère d'intérêt, ainsi qu'une dichotomie présente dans toutes ces classes qui permettra d'assoir notre critique des outils de modélisation mis à notre disposition.

\begin{itemize}
  \item parole : sons voisés <a>, <o> / sons plosifs <pe>, <qe>
  \item vocalisation animale : hululement de chouettes / clics de localisation de chauve souris
  \item musique : chant lyrique / percussions
  \item mécanique : ventilation / marteau piqueur
  \item environnementaux : vent faisant siffler des câbles / gouttes de pluie
\end{itemize}\marginnote{Cette typologie est arbitraire, mais suffisante pour les besoins du propos. Elle est grossièrement ordonnée par période d'intérêt important de la communauté de traitement du signal, le traitement de la parole ayant connu un essor dans les années 1970, la bio acoustique un peu plus tard, la musique dans les années 2000 et les signaux environnementaux dans les années 2010.}

On remarquera que les exemples donnés pour chaque classe sont choisis à dessein. Sans rentrer dans les détails, on notera que l'on retrouve certains sons portant une structuration fréquentielle forte et d'autres une structuration temporelle forte et que la plupart des sons naturels sont une composition de ces deux types de structures. Il est donc néccessaire pour atteindre nos objectifs de disposer d'outils performants pour modéliser conjointement ces deux types de structuration de l'énergie sur le plan temps/fréquence.

\section{Approches temps / fréquence}

Lorsque l'on cherche à décrire un son, deux dimensions émergent : l'intensité et la hauteur. Ces deux dimensions étant respectivement intimement liés au volume et à la fréquence, il est normal de constater que la plupart des modèles de son permettent de manipuler ces deux dernières quantités et ce, de manière dynamique \textit{i.e.} au cours du temps.

En supposant le signal sonore stationnaire sur l'intervalle d'observation, l'outil privilégié pour ce faire est la transformée de Fourier discrète. Cette transformée projette le signal sur une base d'exponentielles complexes:
\begin{eqnarray}
  S[m] &=& \sum_{n=0}^{N} s[n] e^{-jnm/F_s} \\
  s[n] &=&\frac{1}{N}
\end{eqnarray}

Ces exponentielles formant une base, il est possible de revenir au signal d'origine (IDFT(DFT(x))=x). Cette transformée est donc inversible, mais n'est pas à échantillonnage critique car $s\in \mathbb{R}$  et $S in \mathbb{C}$\marginnote{On la calcule de manière efficace grâce à des algorithmes de transformée de Fourier rapides qui exploitent, pour le plus connu d'entre eux, des longueurs de supports en puissance de deux.}.

En considérant le module de cette transformée, on manipule directement l'intensité du son à la fréquence donnée. Le spectre de phase est lui souvent négligé dans les modèles, car il est beaucoup plus difficile à interpréter. Ceci constitue un handicap majeur pour tout les modèles de sons basés sur la transformée de Fourier car cela, comme cela sera discuté dans la suite, pose bien souvent une limite sur la propriété de naturalité, le module et l'exposant étant mathématiquement intrinsèquement lié.

Considérons un premier signal "éprouvette" constitué de deux sinusoides de fréquence et d'amplitude constante:
\begin{equation}
  s_s[n] =
\end{equation} FIGURE
Il est aisé d'estimer les paramètres d'amplitude et de fréquence grâce à l'estimateur suivant :
\begin{eqnarray}
  a_s &=& \\
  f_s &=&
\end{eqnarray} FIGURE
On peut améliorer la précision de ces estimations en réduisant le pas de quantification de l'axe fréquentiel. On utilise pour cela la technique du "zero padding", qui consiste à concatener une série de valeurs nulles au signal observé. La transformée s'opérant alors sur plus de points, sa précision est augmentée. Il est important de bien garder en mémoire que seule la précision est augmentée, la résolution restant dépendante de la largeur du support temporel. \marginnote{Un large échantillon de méthodes sont disponibles pour améliorer la précision de ces estimations par d'autres moyens moins directs, voir \cite{marchand}.}. Augmenter l'intervalle d'observation va donc non seulement influer sur la précision, mais également sur la résolution de la transformée. Ainsi deux sinusoïdes de fréquences proches pourront être "résolues", cad leurs paramètres pourront être estimés en observant directement le spectre d'amplitude. Dans le cas de plusieurs sinusoides, on remplacera le max par une sélection de pics dans le spectre de puissance et on considèrera l'usage d'une fenêtre de type cosinusoidale (hamming, hanning) pour améliorer la localité fréquentielle.

Egalement, dans le cas multi-composantes, on effectue un fenêtrage du signal observé, souvent. En effet, considérer le signal sur un intervalle de temps défini par la largeur de la trame revient à fenêtré le signal par une fenêtre rectangulaire qui a des propriétés spectrales non déisrables.

EQUATION

On note qu'avec des fenêtres cosinusoidales, comme Hamming ou Hanning, le lobe principal s'élargit, d'où une perte locale de résolution, mais permet de réduit considérablement l'importance des lobes secondaires. FIGURE

Considérons un autre signal "éprouvette" constitué d'un dirac :
\begin{equation}
  s_d[n] =
\end{equation} FIGURE
L'estimation du paramètre d'amplitude et de sa position temporelle est triviale dans le domaine temporel. Cette dernière est par contre beaucoup plus difficile à estimer dans le domaine spectral, du fait du caractère non stationnaire du signal analysé.

Pour palier au caractère non stationnaire à long terme de la plupart des signaux naturels, il est courant d'utiliser la transformée de Fourier à court terme (TFCT). Son principe est d'effectuer une série de transformée de Fourier, chacune sur des fenêtres espacées dans le temps:
\begin{equation}
TFCT =
\end{equation}
En prenant le spectre de magnitude de la TFCT, on obtient le bien connu spectrogramme, un outil de manipulation et de visualisation qui trouve son utilité dans de très nombreux domaines d'application. L'espoir ici est que les erreurs de modélisation des non stationarités du signal seront négligeables du fait du faible support temproels des fenêtres sur lesquels on applique la DFT. \marginnote{Dans le cas classique où les fenêtres se recouvrent de moitié, on peut utiliser la MDCT pour conserver un échantillonnage critique \cite{princen1986analysis}.} FIGURE

En considérant la TFCT, il est alors possible de construire un estimateur "spectral" de la position temporelle de notre dirac:
\begin{equation}
t_d =
\end{equation}
Pour améliorer la précision temporelle de cet estimateur, il est courant de réduire le recouvrement entre fenêtres. Cela suppose bien entendu l'usage d'une fenêtre "à rampe" (triangulaire ou cosinusoidale). La encore, il s'agit d'une amélioration de la précision et non de la résolution. Seule la réduction de l'intervalle d'observation permettant de résoudre la position temporelle de deux diracs.

Aux travers de ces exemples, on voit qu'il est possible d'améliorer dans une certaine mesure la précision des estimations que l'on peut faire à partir d'un plan temps/fréquence obtenu grâce à la TFCT, mais que les résolutions temporelles et fréquentielles reste conflictuellement contraintes par la taille de la fenêtre choisie \marginnote{On parle de variables jointe pour le temps et la fréquence, au même titre que la position et la vitesse en mécanique quantique \cite{heisenberg}}.

Le problème se corse alors sensiblement lorsque l'on considère des signaux qui possèdent une localité temporelle et fréquentielle, ce qui est le cas de la plupart des signaux sonores naturels\marginnote{Un exemple iconique étant la note de piano dont la qualité s'exprime autant du côté de la localité temporelle (netteté de l'attaque) que de la localité fréquentielle (pureté des harmoniques). FIGURE}.

Il paraît alors naturel de considérer des approches à résolution multiples. Tout le problème consiste alors à trouver une représentation qui maximise le potentiel apporté par la multi résolution en terme de fidélité en minimisant la perte en manipulabilité.

L'approche la plus simple concetpuellement consiste, à intervalle régulier, à "empiler" plusieurs DFT de taille différente. FIGURE
La perte d'unicité de la représentation faire que l'on se trouve alors face à un problème intractable de sélection d'où une perte innaceptable en manipulabilité.

La propriété d'unicité de la représentation paraissant incontournable, la seule solution consiste alors à partager judicieusement le plan temps / fréquence de manière à mitiger la contrainte posée par le principe d'incertitude. Un immense travail de la communauté de traitement du signal a été de concevoir ce type de transformée, connue maintenant sous le nom de transformée en "ondelettes". \cite{mallat1989theory}.

Même si les travaux théoriques dans ce domaine ont permis d'ouvrir considérablement les possibilités en terme de conception, je me  tiendrai ici à la forme la plus courante en traitement du signal qui consiste en une construction d'un banc de filtre dyadique à facteur de qualité constant. Ce banc de filtre est constitué d'un ensemble filtres passe bande à l'octave, \textit{i.e.} la fréquence de coupure supérieure est égale à deux fois la fréquence de coupure inférieure. En considérant que le banc de filtre est construit de manière itérative en partant des hautes fréquences, et en notant que le signal observé est d'une durée limitée, une partie du spectre en basse fréquence ne peut être capturé. On ajoute alors un filtre passe bas "de terminaison" qui permet de préserver l'unicité de la représentation, souvent appelé "fonction d'échelle". Les sorties de ce banc de filtres peuvent être ensuite rééchantillonné à une fréquence de Nyquist correspondante à la largeur de la bande d'octave du filtre considéré QUID DU FILTRE DE TERMINAISON ?.

Comme le montre les travaux pionniers en ce domaine \cite{kronland1987analysis}, l'application de la transformée en ondelettes paraît avoir d'excellentes propriétés pour le traitement de l'audio, en particulier cette capacité à proposer une analyse multirésolution en préservant la propriété d'unicité. Quelques décennies plus tard, on peut faire le constat que l'utilisation de la transformée en ondelettes reste marginale en traitement de l'audio.

Une première explication peut être que les fonctions de bases de la transformée en ondelettes, \textit{i.e.} les réponses impulsionnelles des filtres passe bande ont des formes particulières, non adaptées à l'audio. On peut en effet aisément retenir cet argument pour des ondelettes de Daubechies de faible longueur, pour des longueurs plus élevées, ou par les ondelettes de morlet.

parler de stabilite à la déformation mel et redressement implicite

lewicki ??

Ceci pourrait expliquer pourquoi cette transformée à pris son essor dans le domaine du traitement d'image, où les discontinuités sont beaucoup plus fortes que pour les signaux sonores\marginnote{En effet, chaque contour d'un objet amène une discontinuité importante dans l'espace couleur, qui, dans le cas du codage, se doit d'être représenté en détail, sous peine d'engendrer des artéfacts de type "lissage" très pénalisant et dans le cas de la reconnaissance, apporte des éléments d'interprétation très importants.}

Une seconde, finalement peut être plus déterminante, peut avoir trait à l'interprétabilité et à la manipulabilité de la transformée. L'interprétation du spectrogramme est extrêmement intuitive et permet une analyse fine du contenu spectral d'un signal audio, ceci avec peu d'expertise. L'interprétation du scaleogram (l'équivalent pour la transformée en ondelettes) reste bien. En ce qui concerne la manipulabilité, l'échantillonage non régulier en temps et en fréquence ne simplifie pas l'expression des transformations que l'ont souhaitent généralement opérer (transposition, étirement, ...).

En tout état de cause, dans le domaine de l'audio, la grande majorité des systèmes de traitement considère une représentation de type TFCT, avec des paramètres de résolution et de précision constants, et adaptés à la tâche. Ce n'est que dans les applications de codage que l'on trouve des mécanismes à résolution multiple de type alterné, implanté grâce des MDCT de trois largeurs de support\cite{brandenburg1999mp3}. Au sein du codeur, une heuristique détermine parmi les trois résolutions poossibles, la résolution la plus adaptée au vu du signal contenu dans l'intervalle d'observation considéré. Cet échantillonage non régulier de l'axe temporel permet une meilleure fidélité et flexibilité si l'heuristique est adaptée, ceci au détriment de la manipulabilité, le plan temps/fréquence induit étant non régulier, ce qui n'est généralement pas un factuer  limitant dans des chaînes de codage.

On considère donc ici que dans l'intervalle d'observation, une source sonore est dominante et que le type de source est structurée soit de manière temporelle soit de manière spectrale. Dans le cas d'un contenu polyphonique avec une structure saillante à la fois en temps et en fréquence, cette approche se révèle bien entendu inefficace. La définition d'une méthode d'analyse/synthèse multirésolution reste donc, avec les éléments présentés ici, un problème encore largement ouvert.

\section{Modélisation sinusoïdale court terme}

Lorsque l'on observe un spectrogramme un instrument de musique tonal (FIGURE), il apparait clairement que l'énergie est concentrée en un ensemble réduit de zones fréquentielles. On dit que ces signaux sont parcimonieux en fréquence. C'est, dans une certaine mesure le cas de la parole\marginnote{En tout cas, il est clair que la "charge sémantique" est portée par cette partie du signal de la parole. En supposant que le récepteur (l'oreille) est capable de décomposer les sons sur l'axe fréquentiel, il fait sens écologiquement de procéder ainsi. Comme le montre les exemples de "sine-wave speech", quelques sinusoïdes (3 ou 4) judicieusement placées aux zones de résonances formantiques suffisent à rendre le signal intelligible \url{http://webpages.mcgill.ca/staff/Group2/abregm1/web/downloadstoc.htm\#23}.}.

En suivant cette observation, on peut considérer l'heuristique des maxima locaux pour extraire de chaque spectre du spectrogramme un ensemble de "pics spectraux", ou "atomes" :

Même si cette technique est motivée par la parcimonie, elle se révèle très robuste à la réduction de cette dernière. En effet, l'expansion de Karhunen Loeve de signaux bruités montre qu'une représentation sinusoidale de ce type de signaux est valide, à condition que les pics soient suffisamment nombreux et de fréquence suffisamment proche pour que la densité spectrale de puissance dans ces zones varie lentement dans le temps \cite{mcaulay} (EXEMPLES SONORES ?). En pratique, dans un compromis favorisant la fidélité et la flexibilité au détriment de la manipulabilité, on choisira $P$ en fonction de contraintes de complexité.

Les paramètres de fréquence, d'amplitude, et de phase de chaque atome peuvent être estimées grâce aux informations données directement par la transformée de Fourier :
\begin{eqnarray}
\end{eqnarray}
Comme évoqué dans la partie précédente, la précision de ces estimations peut être améliorer par des techniques de sur échantillonage en fréquence et en temps, au détriment du coût de calcul. Ceci étant dit, les limites de cette technique sont bien illustrés dans la figure suivante :

% voice_1024_512.eps

Ce problème d'estimation dépassant largement la problématique de la modélisation du signal audio, un effort conséquent d'amélioration des ces estimateurs a été effectué par la communauté de traitement du signal. Les approches les plus efficaces et les plus élégantes pour ce faire se basent sur des relations entre les paramètres spectraux de plusieurs transformées de Fourier effectuées après différents traitements du signal observé. La technique du reassignement spectral\cite{auger1995improving} considère le rapport entre la DFT du signal fenêtré et la DFT du signal fenêtré par la dérivée de la fenêtre :
\begin{equation}
t
\end{equation}
En considérant le rapport de la DFT du signal et celle de la DFT de la dérivée du signal, on obtient une autre série d'estimateurs. On a prouvé l'équivalence théorique de ces dernières à la technique du réassignement, supportée par des expérimentations montrant des performances similaires \cite{lagrangeJaes07}.

L'usage de ces estimateurs permet de reconsidérer l'heuristique utilisée pour sélectionner les atomes candidats. En effet, dans un objectif de manipulabilité, il est important que  avec l'observation  soit en adéquation avec le modèle utilisé. De nombreux critères dits de "sinusoidalité" ont été proposés pour ce faire. Pour ce faire, nous avons proposée une approche \cite{peak-selection} L'algorithme proposé consiste a corréler, pour chaque pic candidat, sa réponse fréquentielle à celle du spectre d'une sinusoïde dont les paramètres sont résultant du processus d'estimation. Le degré de corrélation permet alors de quantifier la pertinence du modèle.
Une étude comparative \cite{wells2010comparative} semble montrer l'intérêt de cette approche en pratique.

Dans cet algorithme, les références au modèle sont ici construites dynamiquement mais peuvent aussi être échantillonnées. On se rapproche alors du principe des algorithmes de poursuites de sous espaces \cite{}. Le principe ici est de s'affranchir des contraintes de la base de Fourier en disposant d'un (très) large dictionnaire d'atomes redondants et de déterminer la combinaison optimale de ces atomes permettant de réduire l'erreur d'approximation.

L'algorithme proposé par Zhang et Mallat \cite{mallat1993matching} permet de résoudre efficacement ce problème en considérant un algorithme glouton, où, itérativement, l'atome mis à l'échelle ayant la meilleure corrélation avec le signal résiduel (égal au signal d'origine au début de l'algorithme) est sélectionné.

L'application directe de ce type d'algorithme à des signaux musicaux peut poser des problèmes, dont certains ont été étudiés par Rémi Gribonval. Par exemple, dans le cas de signaux non stationnaire en amplitude, l'algorithme aura tendance à construire des approximations non satisfaisantes.

La figure illustre deux cas typiques de ce type de non stationarité rencontrés dans les signaux musicaux. Le premier consiste en une composante sinusoidale dont l'amplitude est modulée de manière sinusoidale. C'est une modulation typique d'un tremolo. Le second consiste en une composante sinusoidale dont l'amplitude est modulée exponentiellement. C'est une modulation typique d'une corde frappée ou pincée comme le piano ou le clavecin.

Dans le cas a), l'algorithme MP identifie d'abord une composante avec un support temporel couvrant l'intégralité du signal. Deux autres composantes viennent ensuite annuler certaines parties de cette première. Dans le cas b), le changement abrupt d'énergie étant dificcilement modélisable aves les fonctions de base à disposition, de nombreuses composantes d'annulation sont nécessaires, amenant à un effet de pré écho, l'énergie ajoutée n'étant que partiellement enlevée.

gribonval.png

Pour palier à ces problèmes, des contraintes de non negativité ont été proposé pour améliorer l'algorithme de poursuite \cite{gribonval1996sound}. En réduisant les contributions destructives (enlever de l'énergie amené par des atomes selectionés mais non présente dans le signal d'origine), cette approche est plus efficace au sens où l'énergie globale des atomes (somme des envelopes des atomes) est plus faible cas a)  et plus fidèle cas b).

Il est difficile de critiquer ces approches de poursuites dans le sens où sa pertinence vis à vis de la tâche va grandement dépendre du degré de pertinence du dictionnaire choisi. On notera tout de même que ces approches sont construites avec un objectif d'appromixation et non d'identification. Par exemple dans le cas (a), les deux algorithmes de poursuites sont tout deux à même de bien approximer le signal, mais "n'identifie" pas le phénomène, le dictionnaire n'ayant pas ce type de forme \marginnote{On prefera en tout état de cause la seconde approximation pour des raisons de simplicité. PARLER DE L'INDETERMINATION ?}.

A ce titre, on se trouve donc avec un compromis de modèle favorisant la fidélité et la flexibilité, au détriment de la manipulabilité. Il est en effet difficile, dans le cas d'un dictionnaire très largement redondant de déterminer des fonctions simples de manipulation.

Ces approches, comme la transformée en ondelettes, ont trouvés application plutôt dans le domaine du traitement de l'image, où le caractère hautement non stationnaire des transitions entre objets sont très mal approximé par des fonctions régulières comme celle de Fourier.

\section{Approches sinusoïdales long terme}

\cite{mcaulay}

L'approche court terme effectue des observations discrètes d'un processus de production sonore qui lui est par essence continu. Dans le cas de nombreux instruments de musique, il est raisonnable de considérer que ce processus continu est approximable par une somme de sinusoïdes dont les paramètres varient \textsl{lentement}\marginnote{Typiquement, de l'ordre de la dizaine de Hertz.} dans le temps :
\begin{equation}
t
\end{equation}

En supposant les paramètres connus, le processus de synthèse est aisée à mettre en oeuvre avec les moyens computationels actuels\marginnote{Dans le cas d'un nombre de sinusoide très grand des algorithmes de "pruning" peuvent être mis en place \cite{lagrangeDafx01}.}. Il est également aisé de mette en place des modifications du signal d'intérêt comme la translation, la transposition, ou encore l'étirement, simplement en manipulant les paramètres\marginnote{Ces transformations sont également à faible coût, les paramètres étant échantillonnés à une fréquence environ 1000 fois plus faible que le signal}. On est donc typiquement dans un compromis qui favorise la fidélité et la manipulabilité. Ceci se fait, on le verra par la suite, au détriment de la flexibilité, ce modèle étant applicable à un champ restreint de signaux sonores.

Dans notre étude des algorithmes d'estimation des paramètres long terme, on supposera que le signal analysé est composé d'une ou plusieurs sources dont une grande partie de leur énergie peut être correctement approximée par ce modèle. On fera état ici des approches dites de "restoration" de continuité, qui considèrent connu un modèle court terme du signal analysé mais dont la fiabilité n'est pas pré supposée\marginnote{Ce n'est bien entendu pas la seule approche possible. On peut notamment citer les travaux de Corentin Dubois qui a étudié l'application des techniques de filtrage particulaire pour l'estimation conjointe des paramètres court terme et long terme \cite{dubois2005tracking}, travail étendu à des modèles de sources harmoniques \cite{dubois2007joint}}.


Dans l'article séminal de George Mac Aulay \& al, il est donc proposé "d'identifier" ces composantes long terme en reliant entre eux des atomes de trames successives. L'algorithme proposé est itératif. Supposant un ensemble de composantes long terme à la trame $t$, on va chercher à prolonger ces composantes à la trame $t+1$ en commençant par la composante de plus basse fréquence, tel que la différence entre $$ et $$ est minimale :
\begin{equation}
t
\end{equation}
Dans un principe d'allocation exclusif, cet atome est dès lors réservé, indisponible pour la suite du déroulement de l'algorithme. Chaque atome non réservé devient alors une composante long terme qui sera potentiellement prolongée aves des atomes de la trame suivante\marginnote{On note ici que la structure de données se complexifie sensiblement par rapport à la plupart de celles introduites avec des outils de traitement du signal canoniques, amenant une approche plus "informatique" à une problématique de traitement du signal. Cette modélisation plus "riche" a permis une flexibilité de manipulation qui a donner lieu à un large ensemble d'heuristiques qui ne seront pas étudiées ici, même si elles ont leur intérêt pour la qualité du rendu sonore de ce type d'approche.}.

La contrainte exprimée par l'équation \ref{} favorise des trajectoires fréquentielle constantes. Dans le cas d'un modèle court terme de bonne qualité, par exemple dans le cas d'un signal monophonique à structure harmonique cette heuristique peut être raisonnable. Dans le cas de signaux bruités et/ou polyphoniques, il est utile d'améliorer la finnesse du prédicteur en considérant par exemple un prédicteur linéaire appliqué aux séries temporelles des paramètres long terme. Le faible échantillonage de ces séries temporelles nécessite des prédicteurs particulier comme la méthode de Burg \cite{}.

La contrainte d'évolution lente des paramètres dans le cas d'un modèle stationnaire (prédicteur constant) se traduit nautrellement par un seuil sur le delta de fréquence. L'amélioration du prédicteur nous a également amené à reconsidérer cette étape de sélection.

Les bons résultats en terme de rendu sonore obtenu dans le cas  de la modélisation long terme sous contrainte de débit \cite{lagrangeTaslp06} et l'interpolation de données manquantes \cite{lagrangeJaes05}, montre l'intérêt de la modélisation des modulations long terme, au moins du point de vue perceptif.

Fort de cette observation, Martin Raspaud à étudier un modèle long terme hiérarchique qui permet des manipulations riche comme par exemple de l'étirement temporel de notes vibrées. Le principe est de considérer les paramètres long terme comme des signaux, eux mêmes modélisables comme des sinusoïdes dont les paramètres évoluent (très) lentement en fonction du temps.

D'une grande élégance formelle, d'une grande expressivité et manipulabilité, le modèle long terme n'a pas pu trouver un large spectre spectre d'application du fait d'un défaut clair de fidélité\marginnote{On peut citer pour exemple le codeur STS de Phillips qui n'a pas réussi a concurrencer les approches MDCT.}.

Certaines approches, dites hybrides, consistant à combiner un modèle long terme avec un modèle de bruit et modèle de transitoires ont été proposées pour palier à ce défaut. On tombe alors dans un problème de sélection de modèles que l'on peut espérer mitiger dans le cas d'un signal monophonique\marginnote{on est alors souvent dans le cas d'une analyse experte ou l'intervention humaine est décisive, ce qui peut avoir son intérêt dans certaines applications} mais qui devient  rapidement insoluble dans le cas polyphonique.

EXPLICITER PLUS LES RAISONS ?

\section{Approches temps / fréquence / modulations (10)}

S'il est clair que la décomposition fréquentielle est de première importance, la manière dont l'énergie module au court du temps au sein de ces bandes de fréquences l'est également \marginnote{On peut citer pour exemple le son éminement désagréable d'un moteur thermique deux temps (type mobylette) qui part le mouvement mécanique induit une modulation typique.}. L'importance perceptive de ce type de modulations est particulièrement bien exemplifiée par un exemple sonore produit par John Chowning où des sinusoides d'amplitude et fréquence au début constantes sont ensuite modulées par un signal synthétique composé d'une composante sinusoidale (pour le vibrato) et d'une composante stochastique. Ce signal modulant est ensuite mis à l'échelle pour chaque harmonique. Il est important de considérer que même si ce signal modulant a été judicieusement choisi, il n'est pas issu d'un processus d'estimation à partir de signaux réels.

L'écoute montre clairement que le caractère naturel, voisé, est sensiblement plus élevé avec l'ajout de la modulation \marginnote{Ce stimuli est disponible ici \url{http://webpages.mcgill.ca/staff/Group2/abregm1/web/snd/Track24.mp3} pour écoute sur le site de Al Bregman dédié à l'ASA. Les spécificités techniques du porcessus de synthèse sont décrites ici : \url{http://webpages.mcgill.ca/staff/Group2/abregm1/web/downloadstoc.htm\#24}.}.

\subsection{Modèles perceptifs}

Complétons nos connaissances en prenant cette fois ci, non plus un point de vue physique mais physiologique. En regard des études physiologiques relativement anciennes sur la cochlée \cite{}, l'étude des éléments physiologiques en charge du traitement de ces modulations est relativement récente car probablement sensiblement plus difficile a investiguer. On a néanmoins une bonne confiance dans le fait que le système auditif des mammifères dispose d'éléments de traitement dédiés. On citera donc le modèle de Torsten Dau \cite{dau1997modeling} et celui de Shihab Shamma \cite{fritz2003rapid} qui étend le modèle de Dau en ajoutant une troisième dimension : l'échelle.

Shihab Shamma a étudié certaines cellules du cortex auditif primaire du furet, plus particulièrement ce que l'on appelle leur champ de réponse spectro/temporels ("spectro-temporal receptive fields (strf)"). L'animal est contraint au niveau du crâne, et par opération chirugicale, une aiguille permettant de mesurer l'activité électrique est insérée dans le crâne de l'animal et judicieusement placée. Par exposition d'un ensemble de stimuli comportant des modulations, il est alors possible de mesurer ces strf. Au vu de ce type de réponses, Un modèle de traitement de signal est ensuite proposé.

Dans ce modèle, le signal est donc tout d'abord décomposé sur l'axe fréquentiel. La sortie étant un équivalent du spectrogramme qui est ensuite décomposé une nouvelle fois fréquentiellement en temps et en fréquence grâce à des ondellettes bi-dimensionnelles paramétrées avec un facteur d'échelle. La dimension de l'échelle permet de définir le nombre de bandes qui sont conjointement utilisées pour effectuer cette seconde analyse fréquentielle \marginnote{Ces modèles sont bien entendu sujet à débat dans la communauté de neurophysiologie. Par exemple, le facteur d'échelle est pour Dau non nécessaire pour expliquer les données receuillies grâce à son protocole expérimental.}.

\subsection{Scattering d'ondelettes}

En prenant un point de vue mathématique cette fois ci, Stéphane Mallat a proposé un modèle conceptuellement proche du modèle computationel des STRF proposé par Shihab Shamma. En mathématiques appliquées, et plus particulièrement dans le domaine des sciences des données, on cherche à construire des représentations qui aient de bonnes propriétés d'invariance et de stabilité aux déformations. C'est à dire que l'on souhaite que pour une représentation $\phi(x)$ d'un signal $x$ et d'un signal déformé $\tilde x$ :
\begin{itemize}
  \item invariance : $\phi(\tilde x) = \phi(x)$
  \item stabilité : $ \vert \phi(\tilde x) - \phi(x) | < \epsilon $
\end{itemize}

Précisons ces notions en prenant quelques exemples. Lorsque l'on cherche à reconnaitre l'instrument de musique qui a joué la note enregistrée, on souhaite généralement disposer d'une représentation du signal de cette performance qui soit invariante à certains aspects de la performance comme :
\begin{enumerate}
  \item un changement d'amplitude
  \item une translation en temps
  \item un étirement en temps
\end{enumerate}
En effet, pour la tâche pré-citée, que la note ait été jouée plus ou moins proche du microphone\marginnote{J'écarte ici pour la simplicité du discours les aspects de nuances qui ont une influence non négligeable sur le timbre.}, à un instant donné ou quelques secondes plus tard, à une hauteur donnée ou une autre, pour une durée plus ou moins longue ne devrait pas (trop) modifier notre représentation.

L'invariance au volume est obtenue de manière triviale en normalisant les signaux que l'on souhaite comparer. L'invariance à la translation en temps se traduit dans le domaine de Fourier en une invariance à la translation de phase par la prise du module. On souhaite généralement que l'invariance au volume et à la translation soit complète. En ce qui concerne l'invariance à l'étirement temporel, on souhaite généralement plus que la représentation soit stable à la déformation.

Il est clairement explicité dans \cite{anden2014deep} pourquoi le spectre de magnitude de Fourier n'est pas stable à même un petit étirement temporel. En effet, l'impact de l'étirement selon l'axe des fréquences n'est pas le même. Si un petit étirement déplacera d'une petite quantité les fréquences basses, les fréquences le seront beaucoup plus. Prenons le cas classique d'un signal harmonique de fréquence de fondamentale $440 Hz$, un étirement temporel va réduire la valeur de cette fréquence à disons $430 Hz$ pour un delta de $10 Hz$. Ce delta sera $n$ fois plus grand pour la $nième$ harmonique soit $100 Hz$ pour la dixième harmonique. Pour une transformée de Fourier avec des paniers d'une dizaine de Hertz, la différence entre les deux spectres va croitre très rapidement avec delta car l'énergie des harmoniques supérieures va très vite sortir des paniers où l'énergie des harmoniques se plaçait initialement.

Pour être plus stable à ce type de déformation, il convient alors de "délocaliser" les hautes fréquences de manière plus conséquente que les basses. Suivant les communautés, on obtient cette délocalisation progressive sur l'axe des fréquences avec des transformées à Q constant, de type tiers d'octave (acoustique), des Mels ou des Barks (parole)\marginnote{Cette étude est à mon sens d'importance, car elle permet de placer un cadre mathématique pour mieux expliquer ce qui a été empiriquement vérifié dans de nombreux domaines du traitement de l'audio et motivés jusqu'ici par des arguments essentiellement neuro mimétiques.}.

En se plaçant dans le cadre des ondelettes, on obtient ce type de représentation en délocalisant en temps toutes les bandes de fréquence ce qui induit une perte d'information qu'il convient de compenser. Le principe du scattering permet de répondre élégement à ce problème en cascadant des opérations de décomposition et en utilisant chaque niveau de décomposition pour produire une représentation compacte et informative \marginnote{En dissociant ainsi décomposition et représentation, on peut préserver certaines propriétés d'intérêts comme par exemple l'inversibilité pour la décomposition et la stabilité pour la représentation.}.

Le scattering au premier ordre est donc équivalent en termes conceptuels à une transformée à Q constant. En décomposant les sorties un banc de filtres en ondelettes avec un autre banc de filtres, on capte alors l'information de modulation, \textit{i.e.} comment l'énergie fluctue dans une même bande fréquence. On a vu l'importance de ce type de modulation pour la perception, voir \ref{}, il est donc opportun de d'étudier l'apport du second ordre pour une représentation riche du signal sonore\marginnote{Le processus de cascade. Le troisième ordre est conceptuellement difficile à appréhender et a encore été peu étudié, pour les raisons suivantes 1) pratique : l'énergie au troisième ordre est très faible, 2) neuro-mimétique : aucun modèle perceptif n'explicite un troisième ordre de traitement.}.

L'apport du second ordre a été démontré expérimentalement pour des tâches de modélisation \cite{anden2014deep}.

Nous avons complétés cette investigation en considérant une tâche pertinente pour notre propos : l'étude de la représentation des sons d'instruments de musique du répertoire en considérant des modes de jeux étendus. En effet, si la reconnaissance de l'instrument est considérée comme un problème résoluble par une représentation à Q constant \cite{}, la reconnaissance du mode de jeu\marginnote{et par la même d'une notion plus fine de la notion de timbre musical} comporte des éléments de modulations qui ne sont pas aisément capturés par une représentation à Q constant ou un scattering d'ondelettes à l'ordre un. On montre en effet que l'ajout de l'ordre 2 permet une bien meilleure identification du mode de jeu et permet de proposer au compositeur à la recherche d'un certain timbre, d'une investigation plus aisée d'une grande base de données de sons instrumentaux \cite{}.

En terme d'architecture de décomposition, le scattering suit une organisation de type réceptive, fréquence d'abord et temps ensuite. On verra dans la partie suivante un modèle prenant une approche de type source / filtre donc temps et fréquence ensuite et qui est à ce titre plus directement tourné vers la synthèse.

\section{Approches modales}

En se référant plutôt aux processus physiques de production sonore, les approches modales permettent de proposer des méthodes efficaces pour des outils de synthèse dédiés.

Ces modèles se basent sur un modèle de production de type source / filtre, où la source est généralement décrite en terme de propriétés temporelles, et le filtre en terme de propriétés fréquentielles. Pour un signal de parole, on considèrera que la source peut être soit un train d'impulsions résultant de l'ouverture périodique de l'organe phonatoire nommé \marginnote{à tort} cordes vocales pour la production des sons voisés (voyelles) soit un signal stochastique résultant de la compression du flux respiratoire pour la production des sons plosives ou sifflants (consonnes).

Le modèle source / filtre décorrèlle donc naturellement la contribution de l'excitateur et celle du résonateur, ce qui est particulièrement attrayant lorsque l'on recherche un modèle de son permettant une bonne capacité d'interaction. Pour peu que les modèles utilisés pour les deux parties (source et filtre) soit bien adaptés, on obtient des modèles de sons qui sont souvent fidèles et expressifs \cite{modalys, marseille}. La flexibilité reste malheureusement en deca, car le changement de structures pour la source et le filtre ainsi que leurs modes d'interactions nécessitera le plus souvent des adaptations d'ordre computationels si ces changement sont conséquents.

Nous avons par exemple étudié ce type de modèle pour la synthèse de sons de roulements. Ces sons présentent un challenge pour ce type de synthèse car l'interaction entre la bille et la surface sur laquelle elle roule est complexe.

 \cite{LagrangeTasslp10}

 validation perceptive

 \cite{Murphy11a}

marseille \cite{conan2014synthesis}

On se trouve ici à l'intersection entre modélisation statistique et modélisation physique, dans le sens où l'architecture du modèle de son suit un modèle de production.



On trouve avec ce type de modèle deux propriétés d'importance. En premier lieu, la causalité. Au niveau du modèle de synthèse, un échantillon est strictement considérée comme une composante des échantillons précédents.  En second, cette approche met l'accent sur les propriétés de filtrage des composantes modales, il ne s'agit pas ici de synthétiser un signal riche à partir d'une représentation complète du signal, mais plutôt d'exploiter un modèle source / filtre avec une implantation dédiée de ces deux modules en fonction de la tâche visée.

Même si ce type d'approche est utilisée de manière assez marginale, elle garde à mon sens un intérêt historique pour mettre en perspective les approches modernes décrites dans la suite.

\section{Approches temporelles (10)}

Cette revue des modèles de sons nous a permis d'identifier deux verrous qu'il semble difficile de résoudre de manière conjointe.

Rappelons ici les trois propriétés souhaités :
\begin{enumerate}
  \item
  \item
  \item versatile
\end{enumerate}

En suivant cet ordre, on peut procéder à la constitution d'un "cahier des charges" du modèle idéal qui serait le suivant :
\begin{enumerate}
  \item multirésolution
  \item causal

\end{enumerate}

\cite{wavenet}

techniques introduites initialement pixelrnn \marginnote{La précédence d'application de nouvelle technique entre le domaine de l'image et le domaine de l'audio est quasiment toujouts observée. C'est à mon avis du à deux facteurs, l'utilité et la facilité. Nombreuses sont les applications qui necessitent du traitement de l'image, notamment à cause de la prédominance du visuel dans notre approche du réel. La facilité vient de nombreux facteurs. Un premier est qu'il est plus facile d'approcher les dimensions spatiales qui sont cohérentes entre elles. Le temps est notoirement plus complexe à modéliser. Un second est que l'oeil est notoirement plus tolérant que l'oreille. On peut donner comme exemple sur ce dernier point le morphing. Une simple somme pondérée entre deux images judicieusement cadrée permet d'obtenir des résultats appréciables. Ce type de technique est ineffective en audio où le morphing est encore un problème non résolu.}.

Les résultats obtenus en terme de qualité perceptuelle nous invite à étudier cette approche novatrice qui semble apporter des réponses à la problématique non résolue d'une méthode d'analyse synthèse multi résolution qui soit à la fois fidèle, expressive et versatile.

présentation du principe de traitement de l'information.

réseaux neuronaux, présentation avec une optique traitement du signal (LIRE PAPIER MALLAT) \marginnote{neuromimétisme structurel pour les unités et les réseaux, question du conditionnnement chimique, et des mécanismes de prédiction et d'apprentissage. Mécanismes totalement distincts dans les modèles computationnels, pas d'équivalent en neuro sciences.}

présentation de l'architecture

vocoder

certains aspects peuvent trouver des fondements dans des modèles de sons existants

causalité stricte

source filtre

conditionnement lent

Certains aspects de l'architecture sont spécifiques.

Le plus important étant que l'écoute montre l'absence d'artefacts typiques d'une chaîne de traitement spectral mono résolution comme la tfct.

question du conditonnement



Ces points, et de nombreux autres comme l'impact des fonctions de non linéarité sur la qualité du signal généré sont des questions passionnantes, largement ouvertes en terme de compréhension scientifique.

De part la qualité du traitement et la versatilité de ces approches, leur étude constitue pour moi une opportunité pour la communauté traitement du signal. C'est d'autant plus important que la communauté d'apprentissage artificiel traverse actuellement une crise de sens. Ainsi, une vision fondée sur les principes du traitement de l'information, l'équilibre entre empirique et formalisme. Tout ces éléments qui constitue les fondements du traitement du signal sont à mon avis de grand intérêt pour répondre à des questions, qui au vu du champ d'application extrêmement vaste de ces outils, dépasse les problématiques de la seule communauté des sciences des données, pour devenir un enjeu de société.

\section{Conclusion}

approche source filtre <> latent code
